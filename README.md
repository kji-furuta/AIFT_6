# AI Fine-tuning Toolkit

ğŸš€ **æ—¥æœ¬èªLLMãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®çµ±åˆWebãƒ„ãƒ¼ãƒ«ã‚­ãƒƒãƒˆ**

Dockerãƒ™ãƒ¼ã‚¹ã®çµ±åˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§ã€æ—¥æœ¬èªå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ï¼ˆLLMï¼‰ã®ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’ç°¡å˜ã«å®Ÿè¡Œã§ãã¾ã™ã€‚ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã€LoRAã€QLoRAãªã©è¤‡æ•°ã®æ‰‹æ³•ã‚’Webãƒ–ãƒ©ã‚¦ã‚¶ã‹ã‚‰ç›´æ„Ÿçš„ã«æ“ä½œå¯èƒ½ã§ã™ã€‚

## ğŸŒŸ ä¸»è¦æ©Ÿèƒ½

### ğŸŒ çµ±åˆWebã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- **ãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹UI**: http://localhost:8050 ã§ã‚¢ã‚¯ã‚»ã‚¹
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–**: ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é€²æ—ã®å¯è¦–åŒ–
- **ãƒ¢ãƒ‡ãƒ«ç®¡ç†**: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¸€è¦§ãƒ»é¸æŠãƒ»ç”Ÿæˆ
- **ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: JSONLãƒ•ã‚¡ã‚¤ãƒ«ã®ç°¡å˜ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
- **ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±**: GPUä½¿ç”¨çŠ¶æ³ã¨ãƒ¡ãƒ¢ãƒªç›£è¦–
- **ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ãƒ‡ã‚¶ã‚¤ãƒ³**: å¸å›½å¤§å­¦ãƒ­ã‚´ã¨æ´—ç·´ã•ã‚ŒãŸUI

### ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ‰‹æ³•
- **ğŸ”¥ ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: å…¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°ã«ã‚ˆã‚‹é«˜ç²¾åº¦å­¦ç¿’
- **âš¡ LoRA**: ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŠ¹ç‡çš„å­¦ç¿’ï¼ˆä½ãƒ¡ãƒ¢ãƒªï¼‰
- **ğŸ’ QLoRA**: 4bit/8bité‡å­åŒ–ã«ã‚ˆã‚‹è¶…çœãƒ¡ãƒ¢ãƒªå­¦ç¿’
- **ğŸ§  EWC**: ç¶™ç¶šçš„å­¦ç¿’ã«ã‚ˆã‚‹ç ´æ»…çš„å¿˜å´ã®æŠ‘åˆ¶
- **ğŸ”§ è‡ªå‹•é‡å­åŒ–**: ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¿œã˜ãŸæœ€é©åŒ–

### âœ… ã‚µãƒãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«
æœ€æ–°ã®ã‚µãƒãƒ¼ãƒˆãƒ¢ãƒ‡ãƒ«ãƒªã‚¹ãƒˆã§ã™ã€‚

| ãƒ¢ãƒ‡ãƒ«å | ã‚¿ã‚¤ãƒ— | ç²¾åº¦ | æ¨å¥¨VRAM | ã‚¿ã‚° |
| :--- | :--- | :--- | :--- | :--- |
| **Qwen/Qwen2.5-14B-Instruct** | CausalLM | bfloat16 | 32GB | `multilingual`, `14b`, `instruct` |
| **Qwen/Qwen2.5-32B-Instruct** | CausalLM | bfloat16 | 80GB | `multilingual`, `32b`, `instruct` |
| **cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese** | CausalLM | bfloat16 | 80GB | `japanese`, `32b`, `deepseek` |
| **cyberagent/calm3-22b-chat** | CausalLM | float16 | 48GB | `japanese`, `22b`, `chat` |
| **meta-llama/Meta-Llama-3.1-70B-Instruct** | CausalLM | bfloat16 | 160GB | `multilingual`, `70b`, `instruct` |
| **meta-llama/Meta-Llama-3.1-32B-Instruct** | CausalLM | bfloat16 | 80GB | `multilingual`, `32b`, `instruct` |
| **microsoft/Phi-3.5-32B-Instruct** | CausalLM | bfloat16 | 80GB | `multilingual`, `32b`, `instruct` |
| **microsoft/Orca-2-32B-Instruct** | CausalLM | bfloat16 | 80GB | `multilingual`, `32b`, `instruct` |

### GPUæœ€é©åŒ–
- **Flash Attention 2**: æ³¨æ„æ©Ÿæ§‹ã®é«˜é€ŸåŒ–
- **Gradient Checkpointing**: ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å‰Šæ¸›
- **Mixed Precision**: FP16ã«ã‚ˆã‚‹è¨ˆç®—é«˜é€ŸåŒ–
- **ãƒãƒ«ãƒGPUå¯¾å¿œ**: DataParallel/DistributedDataParallel

### ğŸ§  ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ï¼ˆæ–°æ©Ÿèƒ½ï¼‰
- **å‹•çš„é‡å­åŒ–**: 32B/22Bãƒ¢ãƒ‡ãƒ«ã¯4bitã€7B/8Bãƒ¢ãƒ‡ãƒ«ã¯8bité‡å­åŒ–ã‚’è‡ªå‹•é¸æŠ
- **CPUã‚ªãƒ•ãƒ­ãƒ¼ãƒ‰**: GPUãƒ¡ãƒ¢ãƒªä¸è¶³æ™‚ã®è‡ªå‹•CPUå®Ÿè¡Œ
- **ãƒ¡ãƒ¢ãƒªç›£è¦–**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®ç›£è¦–ã¨è­¦å‘Š
- **ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥**: åŠ¹ç‡çš„ãªãƒ¢ãƒ‡ãƒ«å†åˆ©ç”¨
- **æœ€é©åŒ–ã•ã‚ŒãŸAPI**: ãƒ¡ãƒ¢ãƒªåŠ¹ç‡çš„ãªWeb APIï¼ˆ`app/main_unified.py`ï¼‰

## ğŸ“‹ å¿…è¦ç’°å¢ƒ

### ãƒãƒ¼ãƒ‰ã‚¦ã‚§ã‚¢è¦ä»¶
- **GPU**: NVIDIA GPUï¼ˆCUDAå¯¾å¿œï¼‰
- **ãƒ¡ãƒ¢ãƒª**: æœ€ä½8GB VRAMï¼ˆæ¨å¥¨16GBä»¥ä¸Šï¼‰
- **ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒ¢ãƒª**: 16GBä»¥ä¸Šæ¨å¥¨

### ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢è¦ä»¶
- Python 3.8ä»¥ä¸Šï¼ˆæ¨å¥¨3.11ï¼‰
- CUDA 12.6+
- Docker & Docker Compose
- Git

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ãƒªãƒã‚¸ãƒˆãƒªã®ã‚¯ãƒ­ãƒ¼ãƒ³
```bash
git clone https://github.com/kji-furuta/AI_FT_3.git
cd AI_FT_3
```

### 2. Dockerç’°å¢ƒã®èµ·å‹•
```bash
cd docker
docker-compose up -d --build
```

### 3. Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã®èµ·å‹•
```bash
docker exec ai-ft-container bash /workspace/scripts/start_web_interface.sh
```

### 4. ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¢ã‚¯ã‚»ã‚¹
```
http://localhost:8050
```

### ğŸ¯ ä½¿ç”¨å¯èƒ½ãªæ©Ÿèƒ½
- **ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰**: ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³ã¨ã‚¿ã‚¹ã‚¯ç®¡ç†
- **ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°**: ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨å­¦ç¿’å®Ÿè¡Œ
- **ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ**: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§ã®æ¨è«–
- **ãƒ¢ãƒ‡ãƒ«ç®¡ç†**: åˆ©ç”¨å¯èƒ½ãƒ¢ãƒ‡ãƒ«ã¨å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
- **ãƒãƒ‹ãƒ¥ã‚¢ãƒ«**: `/manual` - è©³ç´°ãªåˆ©ç”¨æ–¹æ³•
- **ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦**: `/system-overview` - æŠ€è¡“ä»•æ§˜

## ğŸ“š ä½¿ç”¨æ–¹æ³•

### ğŸŒ Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆæ¨å¥¨ï¼‰

ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://localhost:8050` ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ä»¥ä¸‹ã®æ©Ÿèƒ½ã‚’åˆ©ç”¨ï¼š

#### 1. ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
1. **ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠãƒ»ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
2. **ãƒ¢ãƒ‡ãƒ«é¸æŠ**: åˆ©ç”¨å¯èƒ½ãªãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰é¸æŠ
3. **è¨­å®šèª¿æ•´**: LoRA/QLoRA/ãƒ•ãƒ«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®é¸æŠ
4. **å®Ÿè¡Œç›£è¦–**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é€²æ—ã¨ãƒ­ã‚°ã®ç¢ºèª

#### 2. ãƒ†ã‚­ã‚¹ãƒˆç”Ÿæˆ
1. **ãƒ¢ãƒ‡ãƒ«é¸æŠ**: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®é¸æŠ
2. **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›**: ç”Ÿæˆã—ãŸã„ãƒ†ã‚­ã‚¹ãƒˆã®å…¥åŠ›
3. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´**: æ¸©åº¦ã€æœ€å¤§é•·ãªã©ã®è¨­å®š
4. **çµæœç¢ºèª**: ç”Ÿæˆã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆã®è¡¨ç¤ºãƒ»ä¿å­˜

#### 3. ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†
- **ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±**: GPUä½¿ç”¨çŠ¶æ³ã¨ãƒ¡ãƒ¢ãƒªç›£è¦–
- **ãƒ¢ãƒ‡ãƒ«ä¸€è¦§**: åˆ©ç”¨å¯èƒ½ãƒ»å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ç®¡ç†
- **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã¨æŠ€è¡“ä»•æ§˜ã®å‚ç…§

### ğŸ”§ APIä½¿ç”¨ï¼ˆä¸Šç´šè€…å‘ã‘ï¼‰

### LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®ä¾‹
```python
from src.models.japanese_model import JapaneseModel
from src.training.lora_finetuning import LoRAFinetuningTrainer, LoRAConfig
from src.training.training_utils import TrainingConfig

# ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ– (æ–°ã—ã„æ¨å¥¨ãƒ¢ãƒ‡ãƒ«)
model = JapaneseModel(
    model_name="cyberagent/calm3-22b-chat"  # ã¾ãŸã¯ "cyberagent/DeepSeek-R1-Distill-Qwen-32B-Japanese"
)

# LoRAè¨­å®š
lora_config = LoRAConfig(
    r=16,
    lora_alpha=32,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    lora_dropout=0.05,
    use_qlora=False
)

# ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š
training_config = TrainingConfig(
    learning_rate=3e-4,
    batch_size=4,
    num_epochs=3,
    output_dir="./outputs/lora_stablelm_3b"
)

# ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼ã®åˆæœŸåŒ–ã¨å®Ÿè¡Œ
trainer = LoRAFinetuningTrainer(model, lora_config, training_config)
trainer.train(train_texts=["æ—¥æœ¬ã®é¦–éƒ½ã¯æ±äº¬ã§ã™ã€‚", "æ—¥æœ¬ã®æœ€é«˜å³°ã¯å¯Œå£«å±±ã§ã™ã€‚"])
```

### ğŸ§  EWCã«ã‚ˆã‚‹ç¶™ç¶šçš„å­¦ç¿’ã®ä¾‹
EWCã¯ã€ä»¥å‰ã®ã‚¿ã‚¹ã‚¯ã®çŸ¥è­˜ã‚’å¿˜ã‚Œã‚‹ã“ã¨ãªãã€æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã‚’ãƒ¢ãƒ‡ãƒ«ã«å­¦ç¿’ã•ã›ã‚‹ãŸã‚ã®æ‰‹æ³•ã§ã™ã€‚

```python
from src.models.japanese_model import JapaneseModel
from src.training.lora_finetuning import LoRAFinetuningTrainer, LoRAConfig
from src.training.training_utils import TrainingConfig
from src.training.ewc_utils import EWCConfig, EWCManager

# 1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã¨æœ€åˆã®ã‚¿ã‚¹ã‚¯ã®ãƒ‡ãƒ¼ã‚¿
model = JapaneseModel("cyberagent/calm3-22b-chat")
task1_data = ["ä¸€èˆ¬çš„ãªçŸ¥è­˜ã«é–¢ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ...", "æ­´å²ã«é–¢ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ..."]

# 2. æœ€åˆã®ã‚¿ã‚¹ã‚¯ã§ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
lora_config = LoRAConfig(r=8, lora_alpha=16)
training_config = TrainingConfig(learning_rate=2e-4, num_epochs=2, output_dir="./outputs/task1_lora")
trainer = LoRAFinetuningTrainer(model, lora_config, training_config)
trained_model = trainer.train(train_texts=task1_data)

# 3. EWCã®æº–å‚™ (Fisheræƒ…å ±è¡Œåˆ—ã®è¨ˆç®—)
ewc_manager = EWCManager(trained_model.model, trained_model.tokenizer)
fisher_matrix = ewc_manager.compute_fisher(task1_data)

# 4. æ–°ã—ã„ã‚¿ã‚¹ã‚¯ã§EWCã‚’ä½¿ã£ã¦ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
ewc_config = EWCConfig(enabled=True, ewc_lambda=0.5, fisher_matrix=fisher_matrix)
training_config_task2 = TrainingConfig(learning_rate=1e-4, num_epochs=2, output_dir="./outputs/task2_ewc_lora")

task2_data = ["ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã«é–¢ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ...", "Pythonã®ã‚³ãƒ¼ãƒ‰ä¾‹..."]
trainer_task2 = LoRAFinetuningTrainer(
    model=trained_model, 
    lora_config=lora_config, 
    training_config=training_config_task2,
    ewc_config=ewc_config # EWCè¨­å®šã‚’æ¸¡ã™
)
final_model = trainer_task2.train(train_texts=task2_data)
```

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
AI_FT_3/
â”œâ”€â”€ app/                          # Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”‚   â”œâ”€â”€ main_unified.py           # çµ±åˆWebã‚µãƒ¼ãƒãƒ¼ï¼ˆç¨¼åƒä¸­ï¼‰
â”‚   â”œâ”€â”€ memory_optimized_loader.py # ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ­ãƒ¼ãƒ€ãƒ¼
â”‚   â””â”€â”€ static/                   # ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ãƒ•ã‚¡ã‚¤ãƒ«
â”‚       â””â”€â”€ logo_teikoku.png      # å¸å›½å¤§å­¦ãƒ­ã‚´
â”œâ”€â”€ templates/                    # HTMLãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
â”‚   â”œâ”€â”€ base.html                 # ãƒ™ãƒ¼ã‚¹ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆãƒ­ã‚´çµ±åˆï¼‰
â”‚   â”œâ”€â”€ index.html                # ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸
â”‚   â”œâ”€â”€ finetune.html             # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ãƒšãƒ¼ã‚¸
â”‚   â””â”€â”€ models.html               # ãƒ¢ãƒ‡ãƒ«ç®¡ç†ãƒšãƒ¼ã‚¸
â”œâ”€â”€ static/                       # é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆtemplatesã¨åŒã˜ãƒ¬ãƒ™ãƒ«ï¼‰
â”‚   â””â”€â”€ logo_teikoku.png          # ãƒ­ã‚´ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆWebé…ä¿¡ç”¨ï¼‰
â”œâ”€â”€ src/                          # ã‚³ã‚¢ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
â”‚   â”œâ”€â”€ models/                   # ãƒ¢ãƒ‡ãƒ«é–¢é€£
â”‚   â”œâ”€â”€ training/                 # ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°
â”‚   â”œâ”€â”€ utils/                    # ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
â”‚   â””â”€â”€ rag/                      # RAGæ©Ÿèƒ½
â”œâ”€â”€ docker/                       # Dockerç’°å¢ƒ
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ scripts/                      # é‹ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ outputs/                      # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ä¿å­˜
â”œâ”€â”€ data/                         # ãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‡ãƒ¼ã‚¿
â”œâ”€â”€ config/                       # åŸºæœ¬è¨­å®š
â”œâ”€â”€ configs/                      # DeepSpeedè¨­å®š
â””â”€â”€ docs/                         # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
    â”œâ”€â”€ API_REFERENCE.md
    â”œâ”€â”€ LARGE_MODEL_SETUP.md
    â””â”€â”€ MULTI_GPU_OPTIMIZATION.md
```

## âœ¨ ä¸»ãªç‰¹å¾´

### ğŸ¯ ç°¡å˜æ“ä½œ
- **ãƒ¯ãƒ³ã‚¯ãƒªãƒƒã‚¯èµ·å‹•**: Docker Composeã§ç’°å¢ƒæ§‹ç¯‰å®Œäº†
- **ãƒ–ãƒ©ã‚¦ã‚¶æ“ä½œ**: ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ä¸è¦ã®WebUI
- **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–**: å­¦ç¿’é€²æ—ã¨GPUä½¿ç”¨çŠ¶æ³ã‚’å¯è¦–åŒ–
- **è‡ªå‹•æœ€é©åŒ–**: ãƒ¢ãƒ‡ãƒ«ã‚µã‚¤ã‚ºã«å¿œã˜ãŸé‡å­åŒ–è¨­å®š
- **ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«UI**: å¸å›½å¤§å­¦ãƒ­ã‚´ã¨æ´—ç·´ã•ã‚ŒãŸãƒ‡ã‚¶ã‚¤ãƒ³

### ğŸš€ é«˜æ€§èƒ½
- **GPUæœ€é©åŒ–**: CUDA 12.6 + PyTorch 2.7.1
- **ãƒ¡ãƒ¢ãƒªåŠ¹ç‡**: å‹•çš„é‡å­åŒ–ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
- **ãƒãƒ«ãƒãƒ¢ãƒ‡ãƒ«å¯¾å¿œ**: 3Bã€œ70Bãƒ¢ãƒ‡ãƒ«ã¾ã§ã‚µãƒãƒ¼ãƒˆ
- **DeepSpeedå¯¾å¿œ**: å°†æ¥ã®å¤§è¦æ¨¡å­¦ç¿’ã«å¯¾å¿œ
- **é™çš„ãƒ•ã‚¡ã‚¤ãƒ«æœ€é©åŒ–**: çµ±åˆã•ã‚ŒãŸãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

### ğŸ¨ UI/UXæ”¹å–„
- **ãƒ­ã‚´çµ±åˆ**: æ ªï¼‰ãƒ†ã‚¤ã‚³ã‚¯ã€€ãƒ­ã‚´ï¼ˆ300px Ã— 150pxï¼‰ã®è¡¨ç¤º
- **ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³**: æ§˜ã€…ãªç”»é¢ã‚µã‚¤ã‚ºã«å¯¾å¿œ
- **ãƒ€ãƒ¼ã‚¯ãƒ†ãƒ¼ãƒ**: æ¿ƒã„èƒŒæ™¯è‰²ã¨è–„ã„æ–‡å­—è‰²ã§è¦–èªæ€§å‘ä¸Š
- **ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ**: åŠ¹ç‡çš„ãªã‚¹ãƒšãƒ¼ã‚¹åˆ©ç”¨

## ğŸ¤ ã‚³ãƒ³ãƒˆãƒªãƒ“ãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³

ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’æ­“è¿ã—ã¾ã™ã€‚ä¸»ãªé–‹ç™ºãƒ–ãƒ©ãƒ³ãƒã¯ `main` ã§ã™ã€‚

1. ãƒªãƒã‚¸ãƒˆãƒªã‚’ãƒ•ã‚©ãƒ¼ã‚¯
2. æ©Ÿèƒ½ãƒ–ãƒ©ãƒ³ãƒã‚’ä½œæˆ (`git checkout -b feature/new-feature`)
3. å¤‰æ›´ã‚’ã‚³ãƒŸãƒƒãƒˆ (`git commit -m 'Add new feature'`)
4. ãƒ–ãƒ©ãƒ³ãƒã«ãƒ—ãƒƒã‚·ãƒ¥ (`git push origin feature/new-feature`)
5. ãƒ—ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯MITãƒ©ã‚¤ã‚»ãƒ³ã‚¹ã®ä¸‹ã§å…¬é–‹ã•ã‚Œã¦ã„ã¾ã™ã€‚

## ğŸ™ è¬è¾

- [Hugging Face Transformers](https://github.com/huggingface/transformers)
- [Hugging Face PEFT](https://github.com/huggingface/peft)
- [BitsAndBytes](https://github.com/TimDettmers/bitsandbytes)
- [Accelerate](https://github.com/huggingface/accelerate)

## ğŸ“š é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹](docs/API_REFERENCE.md) - è©³ç´°ãªAPIä»•æ§˜
- [å¤§è¦æ¨¡ãƒ¢ãƒ‡ãƒ«ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—](docs/LARGE_MODEL_SETUP.md) - 32B+ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šæ–¹æ³•
- [ãƒãƒ«ãƒGPUæœ€é©åŒ–](docs/MULTI_GPU_OPTIMIZATION.md) - åˆ†æ•£å­¦ç¿’ã®è¨­å®š

### ğŸŒ Webãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- **åˆ©ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«**: http://localhost:8050/manual
- **ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦**: http://localhost:8050/system-overview

---

## ğŸ¯ ä»Šã™ãå§‹ã‚ã‚‹

```bash
# 1. ã‚¯ãƒ­ãƒ¼ãƒ³
git clone https://github.com/kji-furuta/AI_FT_3.git
cd AI_FT_3

# 2. èµ·å‹•
cd docker && docker-compose up -d --build

# 3. Webã‚µãƒ¼ãƒãƒ¼é–‹å§‹
docker exec ai-ft-container bash /workspace/scripts/start_web_interface.sh

# 4. ãƒ–ãƒ©ã‚¦ã‚¶ã§ã‚¢ã‚¯ã‚»ã‚¹
# http://localhost:8050
```

**ğŸš€ 5åˆ†ã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹ï¼**

### ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

#### ãƒ­ã‚´ãŒè¡¨ç¤ºã•ã‚Œãªã„å ´åˆ
```bash
# é™çš„ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
docker exec ai-ft-container ls -la /workspace/static/

# ãƒ­ã‚´ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
docker exec ai-ft-container curl -I http://localhost:8050/static/logo_teikoku.png
```

#### Webã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ãŒèµ·å‹•ã—ãªã„å ´åˆ
```bash
# ã‚³ãƒ³ãƒ†ãƒŠã®çŠ¶æ…‹ç¢ºèª
docker ps -a

# ãƒ­ã‚°ã®ç¢ºèª
docker logs ai-ft-container

# æ‰‹å‹•èµ·å‹•
docker exec -d ai-ft-container python -m uvicorn app.main_unified:app --host 0.0.0.0 --port 8050 --reload
```
